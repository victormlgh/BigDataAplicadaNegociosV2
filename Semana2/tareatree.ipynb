{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tarea</h1>\n",
    "<h3>Optimización de la Experiencia de Compra en Instacart: Un Análisis de Árboles de Decisiones, Random Forest y Gradient Boosting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Contexto</h1>\n",
    "\n",
    "El propósito de este proyecto es prever qué productos comprarán los usuarios en el futuro, basándonos en las características del conjunto de datos creado durante la fase de limpieza de datos. Utilizando un conjunto de variables seleccionadas y procesadas cuidadosamente, buscamos anticipar las decisiones de compra de los usuarios. Al analizar estas características y su relación con el comportamiento de compra pasado, podemos desarrollar modelos predictivos que nos ayuden a comprender y pronosticar qué productos es más probable que los usuarios adquieran en el futuro. Este enfoque nos permite tomar decisiones informadas sobre la gestión de inventario, personalización de recomendaciones y estrategias de marketing, lo que mejora la experiencia del usuario y aumenta la eficiencia de los servicios que ofrece Instacart.\n",
    "\n",
    "El conjunto de datos consta de los pedidos de 200,000 usuarios, con cada uno realizando entre 4 y 100 pedidos. Nuestro objetivo es predecir qué productos previamente comprados estarán en el próximo pedido de un usuario. Cada usuario ha comprado varios productos en pedidos anteriores, y tenemos información sobre el order_id de su próximo pedido. Este problema se trata de clasificación, ya que necesitamos prever si cada usuario comprará nuevamente ciertos productos o no, lo cual está indicado por la variable reordered, siendo reordered=1 o reordered=0.\n",
    "\n",
    "Como resultado, hemos identificado varias variables predictoras que describen las características de un producto y el comportamiento del usuario con respecto a uno o varios productos. Estas nuevas variables se generaron al analizar los pedidos anteriores del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Asignación</h1>\n",
    "\n",
    "Después de revisar el cuaderno sobre \"Optimización de la Experiencia de Compra en Instacart mediante Análisis de Árboles de Decisión, Bosques Aleatorios y Impulso Gradiente\", tu tarea consiste en implementar dos modelos basados en los métodos mencionados. Debes fusionar árboles de decisión, bosques aleatorios e impulso gradiente. Posteriormente, evalúa y compara ambos modelos para seleccionar el más eficaz. Finalmente, prueba el modelo seleccionado en el conjunto de datos de pruebas para determinar los productos que necesitan ser reordenados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Código en Python</h2>\n",
    "\n",
    "En esta sección, es fundamental cargar las diferentes bibliotecas que se utilizarán en el estudio para garantizar un análisis efectivo y eficiente de los datos. A continuación, se proporciona un ejemplo de cómo podrías cargar estas bibliotecas en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, procedemos a cargar los datos utilizando la biblioteca Pandas. Puedes descargar los datos desde el aula virtual o el repositorio de <a href='https://drive.google.com/file/d/1ev8BAm9SEttmnwT-2gxik4_Y230UqWl1/view?usp=drive_link'>data</a>, dependiendo de tu preferencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de cargar los datos, es importante verificar su calidad y realizar cualquier limpieza necesaria para garantizar la precisión de nuestro análisis. Aquí tienes algunos pasos comunes que podríamos realizar para verificar y limpiar los datos:\n",
    "\n",
    "Verificar la estructura de los datos: Revisar la forma del DataFrame, el tipo de datos de cada columna y la presencia de valores faltantes.\n",
    "\n",
    "Manejo de valores faltantes: Decidir cómo manejar los valores faltantes, ya sea eliminándolos, imputándolos con algún valor, o utilizando técnicas más avanzadas como el imputado mediante modelos.\n",
    "\n",
    "Corrección de tipos de datos: Convertir los tipos de datos según sea necesario para el análisis.\n",
    "\n",
    "Definir un Random Seed para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Divide tu data para entrenar el modelo y poder hacer pruebas de los modelos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(df.drop('reordered', axis=1), df.reordered, test_size=0.2, random_state=RANDOMSEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Funciones para evaluar los modelos y graficar</h1>\n",
    "\n",
    "Revisa las funciones que utilizamos para evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, probs, train_predictions, train_probs):\n",
    "    \"\"\"Comparar el rendimiento del modelo de aprendizaje automático con la referencia. Calculo estadísticos y Muestra de la curva ROC.\"\"\"\n",
    "    \n",
    "    baseline = {}\n",
    "    \n",
    "    baseline['acurracy'] = accuracy_score(y_val, [1 for _ in range(len(y_val))])\n",
    "    baseline['recall'] = recall_score(y_val, [1 for _ in range(len(y_val))])\n",
    "    baseline['precision'] = precision_score(y_val, [1 for _ in range(len(y_val))])\n",
    "    baseline['f1_score'] = f1_score(y_val, [1 for _ in range(len(y_val))])\n",
    "    baseline['roc'] = 0.5\n",
    "    \n",
    "    results = {}\n",
    "    results['acurracy'] = accuracy_score(y_val, predictions)\n",
    "    results['recall'] = recall_score(y_val, predictions)\n",
    "    results['precision'] = precision_score(y_val, predictions)\n",
    "    results['f1_score'] = f1_score(y_val, predictions)\n",
    "    results['roc'] = roc_auc_score(y_val, probs)\n",
    "\n",
    "    train_results = {}\n",
    "    train_results['acurracy'] = accuracy_score(y_train, train_predictions)\n",
    "    train_results['recall'] = recall_score(y_train, train_predictions)\n",
    "    train_results['precision'] = precision_score(y_train, train_predictions)\n",
    "    train_results['f1_score'] = f1_score(y_train, train_predictions)\n",
    "    train_results['roc'] = roc_auc_score(y_train, train_probs)\n",
    "\n",
    "    for metric in ['acurracy', 'recall', 'precision', 'f1_score', 'roc']:\n",
    "        display(f'Base de comparación {metric.capitalize()}: {round(baseline[metric], 2)} Prueba: {round(results[metric], 2)} Entrenamiento: {round(train_results[metric], 2)}')\n",
    "\n",
    "    #Calcular tasas de falsos positivos y tasas de verdaderos positivos.\n",
    "    base_fpr, base_tpr, _ = roc_curve(y_val, [1 for _ in range(len(y_val))])\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_val, probs)\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'Base de comparación')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'Modelo')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Tasa de Falsos Positivos'); plt.ylabel('Tasa de Verdaderos Positivos'); plt.title('Curva ROC')\n",
    "\n",
    "def plot_confusion_matrix(predictions):\n",
    "\n",
    "    cm = confusion_matrix(y_val, predictions)\n",
    "    classes = ['Sin reorden', 'Con reorden']\n",
    "\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Oranges)\n",
    "    plt.title('Matriz de confusión', size = 24)\n",
    "    plt.colorbar(aspect=4)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n",
    "    plt.yticks(tick_marks, classes, size = 14)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), fontsize = 20,\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.grid(None)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta Verdadera')\n",
    "    plt.xlabel('Etiqueta predicha')\n",
    "\n",
    "def plot_features(model):\n",
    "    feat = list(X_train.columns)\n",
    "    fi = pd.DataFrame({'feature': feat,\n",
    "                    'importance': model.feature_importances_}).\\\n",
    "                        sort_values('importance', ascending = False)\n",
    "    \n",
    "    x_values = list(range(len(fi['importance'])))\n",
    "    plt.bar(x_values, fi['importance'], orientation = 'vertical')\n",
    "    plt.xticks(x_values, fi['feature'], rotation='vertical')\n",
    "    plt.ylabel('importance')\n",
    "    plt.xlabel('Características')\n",
    "    plt.title('Importancias de las características')\n",
    "\n",
    "def plot_tree(model):\n",
    "    tree.plot_tree(model, \n",
    "                   feature_names=X_train.columns,\n",
    "                   filled=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento de los modelos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el primer modelo a entrenar. Dado el tamaño de los datos, es recomendable limitar la complejidad del modelo para evitar tiempos de entrenamiento prolongados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a determinar los nodos y la profundidad del modelo. Es importante ajustar estos parámetros para equilibrar la capacidad de aprendizaje del modelo y evitar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar las predicciones de probabilidad y las predicciones para los datos de entrenamiento y de prueba con el primer modelo. Esto nos permitirá evaluar el desempeño del modelo en ambos conjuntos de datos y comprender su capacidad para generalizar a datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_probs = model.predict_proba(X_train)[:, 1]\n",
    "#probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#train_predictions = model.predict(X_train)\n",
    "#predictions = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model()\n",
    "plot_confusion_matrix()\n",
    "plot_features()\n",
    "plot_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el segundo modelo a entrenar. Dado el tamaño de los datos, es recomendable limitar la complejidad del modelo para evitar tiempos de entrenamiento prolongados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a determinar los nodos y la profundidad del modelo. Es importante ajustar estos parámetros para equilibrar la capacidad de aprendizaje del modelo y evitar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar las predicciones de probabilidad y las predicciones para los datos de entrenamiento y de prueba con el segundo modelo. Esto nos permitirá evaluar el desempeño del modelo en ambos conjuntos de datos y comprender su capacidad para generalizar a datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comparar los resultados de ambos modelos y luego explicaremos por qué optamos por utilizar uno sobre el otro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prueba del modelo con nuevo datos</h1>\n",
    "\n",
    "Carga el nuevo conjunto de datos de pruebas, lo puedes descargar desde <a href='https://drive.google.com/file/d/1GfmCmZMKoosYaO_5vZW9NxlrHc1p32wc/view?usp=drive_link'>aqui</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar las predicciones de probabilidad y las predicciones para los datos nuevos con el modelo seleccionado. Esto nos permitirá ver el comportamiento del modelo con datos nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Discusión y Conclusión</h1>\n",
    "\n",
    "Presenta tus conclusiones sobre el trabajo llevado a cabo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Referencia</h1>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
