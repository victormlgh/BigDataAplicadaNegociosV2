{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tarea</h1>\n",
    "<h3>Interacciones que Conducen a Recomendaciones: Un Sistema de Recomendación de Artículos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Contexto</h1>\n",
    "\n",
    "En el panorama empresarial actual, la colaboración y el intercambio de conocimientos son cruciales. Plataformas como Deskdrop facilitan esto al permitir a los empleados compartir información relevante. Deskdrop, desarrollado por una empresa líder en tecnología, es una plataforma dinámica donde los profesionales comparten artículos y recursos. Además de difundir información, fomenta la colaboración y el diálogo entre equipos, impulsando la innovación y el crecimiento.\n",
    "\n",
    "Para mejorar la experiencia del usuario, se propone un sistema de recomendación inteligente basado en algoritmos avanzados. Este sistema utiliza el análisis de contenido y el comportamiento del usuario para ofrecer recomendaciones personalizadas. El artículo explora el diseño e implementación de este sistema y su impacto en Deskdrop, mostrando cómo las interacciones de los usuarios, combinadas con técnicas de aprendizaje automático y procesamiento de lenguaje natural, generan recomendaciones precisas y contextualizadas.\n",
    "\n",
    "El estudio se basa en datos de 12 meses de Deskdrop, que incluyen alrededor de 73,000 interacciones de usuarios y más de 3,000 artículos compartidos. Estos datos detallan atributos de artículos y registros de interacciones de usuarios, lo que permite un seguimiento a largo plazo de preferencias. El entorno de datos ofrece una oportunidad única para comprender las dinámicas de interacción y desarrollar sistemas de recomendación que mejoren la experiencia del usuario y la relevancia del contenido compartido.\n",
    "\n",
    "<<h1>Asignación</h1>\n",
    "\n",
    "Después de revisar el cuaderno sobre \"Interacciones que Conducen a Recomendaciones: Un Sistema de Recomendación de Artículos\", tenemos el objetivo de desarrollar un sistema de recomendación basado en Big Data para la plataforma Deskdrop con el fin de presentar artículos relevantes y de interés para cada usuario, mejorando así su experiencia y participación en la plataforma.. Posteriormente, evalúa y compara ambos modelos para seleccionar el más eficaz. Finalmente, prueba el modelo seleccionado en el conjunto de datos de pruebas para determinar los productos que necesitan ser reordenados.\n",
    "\n",
    "\n",
    "Como experto en Big Data, se le solicita desarrollar este sistema de recomendación utilizando técnicas avanzadas de análisis de datos y aprendizaje automático. El sistema deberá analizar los datos de interacción de los usuarios con la plataforma, así como las características de los artículos compartidos, para generar recomendaciones precisas y contextualizadas.\n",
    "\n",
    "<h1>Tareas</h1>\n",
    "\n",
    "- Recopilación y análisis de datos: Obtener y analizar datos históricos de interacción de los usuarios con la plataforma, incluyendo información sobre artículos compartidos, comentarios, me gusta, y visualizaciones.\n",
    "- Preprocesamiento de datos: Limpiar y preparar los datos para su posterior análisis, incluyendo la normalización de texto y la extracción de características relevantes.\n",
    "- Desarrollo de algoritmos de recomendación: Diseñar y desarrollar algoritmos de recomendación basados en técnicas de filtrado colaborativo, filtrado basado en contenido, o una combinación de ambos.\n",
    "- Evaluación del sistema: Evaluar el rendimiento del sistema de recomendación utilizando métricas adecuadas, como precisión, cobertura y diversidad.\n",
    "- Implementación del sistema: Implementar el sistema de recomendación en la plataforma [Nombre de la Plataforma], asegurando su integración sin problemas con la infraestructura existente.\n",
    "- Optimización y ajuste: Realizar ajustes y optimizaciones en el sistema de recomendación según sea necesario para mejorar su rendimiento y precisión.\n",
    "\n",
    "<h1>Código en Python</h1>\n",
    "\n",
    "En esta sección, es fundamental cargar las diferentes bibliotecas que se utilizarán en el estudio para garantizar un análisis efectivo y eficiente de los datos. A continuación, se proporciona un ejemplo de cómo podrías cargar estas bibliotecas en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, procedemos a cargar los datos utilizando la biblioteca Pandas. Puedes descargar los datos desde el aula virtual o el repositorio de <a href='https://drive.google.com/file/d/1b2o9RS4jty1ATkxszRQlmEEEdQfbM2IU/view?usp=drive_link'>datos</a>, dependiendo de tu preferencia. \n",
    "\n",
    "Primero cargamos y visalizamo los datos de los artículos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSEED=56\n",
    "\n",
    "#adf = pd.read_csv('')\n",
    "#display(adf.shape)\n",
    "#display(adf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego cargamos el conjunto de datos de users_interactions que contiene registros de interacciones de usuarios en artículos compartidos. Se puede relacionar con articles_shared.csv mediante la columna contentId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##uidf = pd.read_csv('')\n",
    "#display(uidf.shape)\n",
    "#display(uidf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Análisis exploratorio de datos</h1>\n",
    "\n",
    "Debemos convertir los datos de timestamp al formato de datetime para las interacciones de los usuarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uidf['datetime'] = pd.to_datetime(uidf['timestamp'], unit='s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos interesa graficar el número de interacciones por día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf = uidf.groupby([pd.Grouper(key='datetime', freq='D')]).agg({'eventType':'count'}).reset_index()\n",
    "\n",
    "#sns.set_theme(style='whitegrid', rc={'figure.figsize':(6, 4)})\n",
    "#plt.title('Número de interacciones por día', fontsize=13)\n",
    "#plt.xlabel('Fecha', fontsize=11)\n",
    "#plt.ylabel('Cantidad de Interacciones', fontsize=11)\n",
    "#sns.lineplot(data=gdf, y=\"eventType\", x='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos convertir los datos de timestamp al formato de datetime para los artículos\n",
    "\n",
    "Nos interesa graficar el número de artículos por día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adf['datetime'] = pd.to_datetime(adf['timestamp'], unit='s')\n",
    "#gdf = adf.groupby([pd.Grouper(key='datetime', freq='D')]).agg({'eventType':'count'}).reset_index()\n",
    "\n",
    "#sns.set_theme(style='whitegrid', rc={'figure.figsize':(6, 4)})\n",
    "#plt.title('Número de artículos compartidos por día', fontsize=13)\n",
    "#plt.xlabel('Fecha', fontsize=11)\n",
    "#plt.ylabel('Cantidad de Artículos', fontsize=11)\n",
    "#sns.lineplot(data=gdf, y=\"eventType\", x='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Categorización de los datos</h2>\n",
    "\n",
    "Dado que hay diversos tipos de interacciones, asignamos a cada una un peso o fuerza, suponiendo que, por ejemplo, un comentario en un artículo refleja un mayor interés por parte del usuario que un \"me gusta\" o una simple vista. Modifica los valores para representar la fuerza que entiendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_strength = {\n",
    "   'VIEW': 1,\n",
    "   'LIKE': 2, \n",
    "   'BOOKMARK': 3, \n",
    "   'FOLLOW': 4,\n",
    "   'COMMENT CREATED': 5,  \n",
    "}\n",
    "\n",
    "uidf['eventStrength'] = uidf['eventType'].apply(lambda x: event_strength[x])\n",
    "display(uidf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determina los usuarios que tienen mas de 5 interacciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Número total de usuarios que han interactuado en la plataforma: %d' % len(uidf['personId'].unique()))\n",
    "\n",
    "count_ui = uidf.groupby(['personId', 'contentId']).size().groupby('personId').size()\n",
    "users5i_df = count_ui[count_ui >= 5].reset_index()[['personId']]\n",
    "display('Cantidad total de usuarios que han realizado al menos 5 interacciones en la plataforma: %d' % len(users5i_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinar la cantidad de interacciones de los usuarios que tienen mas 5 interacciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Número total de interacciones en la plataforma: %d' % len(uidf))\n",
    "uidf= uidf[uidf['personId'].isin(users5i_df['personId'].tolist())]\n",
    "display('Cantidad total de interacciones de usuarios que han realizado al menos 5 interacciones en la plataforma: %d' % len(uidf))\n",
    "display(uidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "idf = uidf.groupby(['personId', 'contentId'])['eventStrength'].sum().apply(smooth_user_preference).reset_index()\n",
    "display('Número de interacciones distintas entre usuario y artículo.: %d' % len(idf))\n",
    "display(idf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Divide tu data para entrenar el modelo y poder hacer pruebas de los modelos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(idf, stratify=idf['personId'], test_size=0.2, random_state=RANDOMSEED)\n",
    "\n",
    "display(train_df.shape)\n",
    "display(val_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexa los datos para mejor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = idf.set_index('personId')\n",
    "train_df = train_df.set_index('personId')\n",
    "val_df = val_df.set_index('personId')\n",
    "display(idf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento de los modelos</h1>\n",
    "\n",
    "<h2>Basado en Popularidad </h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = idf.groupby('contentId')['eventStrength'].sum().sort_values(ascending=False).reset_index()\n",
    "pop_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisa las funciones que utilizamos para evaluar los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions):\n",
    "    interacted_items = interactions.loc[person_id]['contentId']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(user_id, items_to_ignore=[], verbose=False):\n",
    "    # Recommend the more popular items that the user hasn't seen yet.\n",
    "    recommendations_df = pop_df[~pop_df['contentId'].isin(items_to_ignore)].sort_values('eventStrength', ascending = False)\n",
    "\n",
    "    if verbose:\n",
    "            recommendations_df = recommendations_df.merge(adf, how = 'left', on = 'contentId')[['eventStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "            \n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_interacted_items_sample(person_id, sample_size, seed=RANDOMSEED):\n",
    "    interacted_items = get_items_interacted(person_id, idf)\n",
    "    all_items = set(adf['contentId'])\n",
    "    non_interacted_items = all_items - interacted_items\n",
    "\n",
    "    random.seed(seed)\n",
    "    non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "    return set(non_interacted_items_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hit_top_n(item_id, recommended_items, topn):        \n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "        except:\n",
    "            index = -1\n",
    "        hit = int(index in range(0, topn))\n",
    "        return hit, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model_for_user(person_id):\n",
    "    interacted_values_testset = val_df.loc[person_id]\n",
    "    if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "        person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "    else:\n",
    "        person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "    \n",
    "    interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "    person_recs_df = recommend_items(person_id, items_to_ignore=get_items_interacted(person_id, train_df))\n",
    "\n",
    "    hits_at_5_count = 0\n",
    "    hits_at_10_count = 0\n",
    "    for item_id in person_interacted_items_testset:\n",
    "        non_interacted_items_sample = get_not_interacted_items_sample(person_id, sample_size=100, seed=RANDOMSEED)\n",
    "\n",
    "        items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "        valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "        valid_recs = valid_recs_df['contentId'].values\n",
    "        hit_at_5, index_at_5 = verify_hit_top_n(item_id, valid_recs, 5)\n",
    "        hits_at_5_count += hit_at_5\n",
    "        hit_at_10, index_at_10 = verify_hit_top_n(item_id, valid_recs, 10)\n",
    "        hits_at_10_count += hit_at_10\n",
    "\n",
    "    recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "    recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "    person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                        'hits@10_count':hits_at_10_count, \n",
    "                        'interacted_count': interacted_items_count_testset,\n",
    "                        'recall@5': recall_at_5,\n",
    "                        'recall@10': recall_at_10}\n",
    "    return person_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el primer modelo a entrenar. \n",
    "\n",
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_metrics = []\n",
    "for idx, person_id in enumerate(list(val_df.index.unique().values)):\n",
    "    person_metrics = evaluate_model_for_user(person_id)  \n",
    "    person_metrics['_person_id'] = person_id\n",
    "    people_metrics.append(person_metrics)\n",
    "\n",
    "popularity_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
    "\n",
    "popularity_recall_at_5 = popularity_df['hits@5_count'].sum() / float(popularity_df['interacted_count'].sum())\n",
    "popularity_recall_at_10 = popularity_df['hits@10_count'].sum() / float(popularity_df['interacted_count'].sum())\n",
    "\n",
    "popularity_metrics = {'modelName': 'Popularity',\n",
    "                    'recall@5': popularity_recall_at_5,\n",
    "                    'recall@10': popularity_recall_at_10}    \n",
    "\n",
    "display('Métricas de evaluación del modelo de popularidad incluyen el recall para los top 5 y top 10 recomendaciones %s' % popularity_metrics)\n",
    "popularity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h2>Basado en Contenido</h2>\n",
    "\n",
    "Revisa las funciones que utilizamos para evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n",
    "\n",
    "item_ids = adf['contentId'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(adf['title'] + \"\" + adf['text'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "display(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_profile(item_id):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    return item_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_profiles(ids):\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_users_profile(person_id, interactions_indexed_df):\n",
    "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\n",
    "    \n",
    "    \n",
    "    user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1)\n",
    "    #Weighted average of item profiles by the interactions strength\n",
    "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_item_strengths_weighted_avg= np.asarray(user_item_strengths_weighted_avg) #np.matrix is not supported. Please convert to a numpy array with np.asarray.\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "\n",
    "    return user_profile_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_users_profiles(): \n",
    "    interactions_indexed_df = train_df[train_df['contentId'].isin(adf['contentId'])]\n",
    "    user_profiles = {}\n",
    "    for person_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_profiles = build_users_profiles()\n",
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_items_to_user_profile(person_id, topn=1000):\n",
    "    #Computes the cosine similarity between the user profile and all item profiles\n",
    "    cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
    "    #Gets the top similar items\n",
    "    similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "    #Sort the similar items by similarity\n",
    "    similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "    return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_cont_items(user_id, items_to_ignore=[], verbose=False):\n",
    "    similar_items = get_similar_items_to_user_profile(user_id)\n",
    "    #Ignores items the user has already interacted\n",
    "    similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))        \n",
    "    recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'recStrength'])\n",
    "\n",
    "    if verbose:\n",
    "            recommendations_df = recommendations_df.merge(adf, how = 'left', on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "            \n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cont_model_for_user(person_id):\n",
    "    interacted_values_testset = val_df.loc[person_id]\n",
    "    if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "        person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "    else:\n",
    "        person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "    \n",
    "    interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "    person_recs_df = recommend_cont_items(person_id, items_to_ignore=get_items_interacted(person_id, train_df))\n",
    "\n",
    "    hits_at_5_count = 0\n",
    "    hits_at_10_count = 0\n",
    "    for item_id in person_interacted_items_testset:\n",
    "        non_interacted_items_sample = get_not_interacted_items_sample(person_id, sample_size=100, seed=RANDOMSEED)\n",
    "\n",
    "        items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "        valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "        valid_recs = valid_recs_df['contentId'].values\n",
    "        hit_at_5, index_at_5 = verify_hit_top_n(item_id, valid_recs, 5)\n",
    "        hits_at_5_count += hit_at_5\n",
    "        hit_at_10, index_at_10 = verify_hit_top_n(item_id, valid_recs, 10)\n",
    "        hits_at_10_count += hit_at_10\n",
    "\n",
    "    recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "    recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "    person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                        'hits@10_count':hits_at_10_count, \n",
    "                        'interacted_count': interacted_items_count_testset,\n",
    "                        'recall@5': recall_at_5,\n",
    "                        'recall@10': recall_at_10}\n",
    "    return person_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el modelo basado en contenido a entrenar.\n",
    "\n",
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "people_metrics = []\n",
    "for idx, person_id in enumerate(list(val_df.index.unique().values)):\n",
    "    person_metrics = evaluate_cont_model_for_user(person_id)  \n",
    "    person_metrics['_person_id'] = person_id\n",
    "    people_metrics.append(person_metrics)\n",
    "\n",
    "content_df = pd.DataFrame(people_metrics) \\\n",
    "                    .sort_values('interacted_count', ascending=False)\n",
    "\n",
    "content_recall_at_5 = content_df['hits@5_count'].sum() / float(content_df['interacted_count'].sum())\n",
    "content_recall_at_10 = content_df['hits@10_count'].sum() / float(content_df['interacted_count'].sum())\n",
    "\n",
    "content_metrics = {'modelName': 'Content',\n",
    "                    'recall@5': content_recall_at_5,\n",
    "                    'recall@10': content_recall_at_10}    \n",
    "\n",
    "print('Métricas de evaluación del modelo de contenido incluyen el recall para los top 5 y top 10 recomendaciones %s' % content_metrics)\n",
    "content_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Colaborativo</h2>\n",
    "\n",
    "\n",
    "Revisa las funciones que utilizamos para evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items_pivot_matrix_df = train_df.pivot(columns='contentId', values='eventStrength').fillna(0)\n",
    "users_items_pivot_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items_pivot_matrix = users_items_pivot_matrix_df.values\n",
    "users_items_pivot_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ids = list(users_items_pivot_matrix_df.index)\n",
    "users_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items_pivot_sparse_matrix = csr_matrix(users_items_pivot_matrix)\n",
    "users_items_pivot_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUMBER_OF_FACTORS_MF = 15\n",
    "\n",
    "U, sigma, Vt = svds(users_items_pivot_sparse_matrix, k = NUMBER_OF_FACTORS_MF)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "display(U.shape)\n",
    "display(sigma.shape)\n",
    "display(Vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "all_user_predicted_ratings_norm = (all_user_predicted_ratings - all_user_predicted_ratings.min()) / (all_user_predicted_ratings.max() - all_user_predicted_ratings.min())\n",
    "\n",
    "all_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_preds_df = pd.DataFrame(all_user_predicted_ratings_norm, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\n",
    "cf_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_collab_items(user_id, items_to_ignore=[], verbose=False):\n",
    "        # Get and sort the user's predictions\n",
    "        sorted_user_predictions = cf_preds_df[user_id].sort_values(ascending=False).reset_index().rename(columns={user_id: 'recStrength'})\n",
    "\n",
    "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['contentId'].isin(items_to_ignore)].sort_values('recStrength', ascending = False)\n",
    "\n",
    "        if verbose:\n",
    "            recommendations_df = recommendations_df.merge(adf, how = 'left', on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "\n",
    "        return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_collab_model_for_user(person_id):\n",
    "    interacted_values_testset = val_df.loc[person_id]\n",
    "    if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "        person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "    else:\n",
    "        person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "    \n",
    "    interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "    person_recs_df = recommend_collab_items(person_id, items_to_ignore=get_items_interacted(person_id, train_df))\n",
    "\n",
    "    hits_at_5_count = 0\n",
    "    hits_at_10_count = 0\n",
    "\n",
    "    for item_id in person_interacted_items_testset:\n",
    "        non_interacted_items_sample = get_not_interacted_items_sample(person_id, sample_size=100, seed=RANDOMSEED)\n",
    "\n",
    "        items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "        valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "        valid_recs = valid_recs_df['contentId'].values\n",
    "        hit_at_5, index_at_5 = verify_hit_top_n(item_id, valid_recs, 5)\n",
    "        hits_at_5_count += hit_at_5\n",
    "        hit_at_10, index_at_10 = verify_hit_top_n(item_id, valid_recs, 10)\n",
    "        hits_at_10_count += hit_at_10\n",
    "\n",
    "    recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "    recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "    person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                        'hits@10_count':hits_at_10_count, \n",
    "                        'interacted_count': interacted_items_count_testset,\n",
    "                        'recall@5': recall_at_5,\n",
    "                        'recall@10': recall_at_10}\n",
    "    return person_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el modelo Colaborativo a entrenar. \n",
    "\n",
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_metrics = []\n",
    "for idx, person_id in enumerate(list(val_df.index.unique().values)):\n",
    "    person_metrics = evaluate_collab_model_for_user(person_id)  \n",
    "    person_metrics['_person_id'] = person_id\n",
    "    people_metrics.append(person_metrics)\n",
    "\n",
    "collaborative_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
    "\n",
    "collaborative_recall_at_5 = collaborative_df['hits@5_count'].sum() / float(collaborative_df['interacted_count'].sum())\n",
    "collaborative_recall_at_10 = collaborative_df['hits@10_count'].sum() / float(collaborative_df['interacted_count'].sum())\n",
    "\n",
    "collaborative_metrics = {'modelName': 'Collaborative',\n",
    "                    'recall@5': collaborative_recall_at_5,\n",
    "                    'recall@10': collaborative_recall_at_10}    \n",
    "\n",
    "print('Métricas de evaluación del modelo colaborativo incluyen el recall para los top 5 y top 10 recomendaciones %s' % collaborative_metrics)\n",
    "collaborative_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Métodos Híbridos</h2>\n",
    "\n",
    "Revisa las funciones que utilizamos para evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid_items(person_id, items_to_ignore=[], cb_ensemble_weight=1, cf_ensemble_weight=100, verbose=False):\n",
    "        cb_recs_df = recommend_cont_items(person_id, items_to_ignore=items_to_ignore).rename(columns={'recStrength': 'recStrengthCB'})\n",
    "        cf_recs_df = recommend_collab_items(person_id, items_to_ignore=items_to_ignore).rename(columns={'recStrength': 'recStrengthCF'})\n",
    "        recs_df = cb_recs_df.merge(cf_recs_df, how = 'outer', on = 'contentId').fillna(0.0)\n",
    "        \n",
    "        recs_df['recStrengthHybrid'] = (recs_df['recStrengthCB'] * cb_ensemble_weight) + (recs_df['recStrengthCF'] * cf_ensemble_weight)\n",
    "        \n",
    "        recommendations_df = recs_df.sort_values('recStrengthHybrid', ascending=False)\n",
    "\n",
    "        if verbose:\n",
    "            recommendations_df = recommendations_df.merge(adf, how = 'left', on = 'contentId')[['recStrengthHybrid', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "        return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid_model_for_user(person_id):\n",
    "    interacted_values_testset = val_df.loc[person_id]\n",
    "    if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "        person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "    else:\n",
    "        person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "    \n",
    "    interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "    person_recs_df = recommend_hybrid_items(person_id, items_to_ignore=get_items_interacted(person_id, train_df))\n",
    "\n",
    "    hits_at_5_count = 0\n",
    "    hits_at_10_count = 0\n",
    "    for item_id in person_interacted_items_testset:\n",
    "        non_interacted_items_sample = get_not_interacted_items_sample(person_id, sample_size=100, seed=RANDOMSEED)\n",
    "\n",
    "        items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "        valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "        valid_recs = valid_recs_df['contentId'].values\n",
    "        hit_at_5, index_at_5 = verify_hit_top_n(item_id, valid_recs, 5)\n",
    "        hits_at_5_count += hit_at_5\n",
    "        hit_at_10, index_at_10 = verify_hit_top_n(item_id, valid_recs, 10)\n",
    "        hits_at_10_count += hit_at_10\n",
    "\n",
    "    recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "    recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "    person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                        'hits@10_count':hits_at_10_count, \n",
    "                        'interacted_count': interacted_items_count_testset,\n",
    "                        'recall@5': recall_at_5,\n",
    "                        'recall@10': recall_at_10}\n",
    "    return person_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el modelo hibrido a entrenar.\n",
    "\n",
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_metrics = []\n",
    "for idx, person_id in enumerate(list(val_df.index.unique().values)):\n",
    "    #if idx % 100 == 0 and idx > 0:\n",
    "    #    print('%d users processed' % idx)\n",
    "    person_metrics = evaluate_hybrid_model_for_user(person_id)  \n",
    "    person_metrics['_person_id'] = person_id\n",
    "    people_metrics.append(person_metrics)\n",
    "\n",
    "hybrid_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
    "\n",
    "hybrid_recall_at_5 = hybrid_df['hits@5_count'].sum() / float(hybrid_df['interacted_count'].sum())\n",
    "hybrid_recall_at_10 = hybrid_df['hits@10_count'].sum() / float(hybrid_df['interacted_count'].sum())\n",
    "\n",
    "hybrid_metrics = {'modelName': 'Hybrid',\n",
    "                    'recall@5': hybrid_recall_at_5,\n",
    "                    'recall@10': hybrid_recall_at_10}    \n",
    "\n",
    "print('Métricas de evaluación del modelo hibrido incluyen el recall para los top 5 y top 10 recomendaciones %s' % hybrid_metrics)\n",
    "hybrid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Resultado</h1>\n",
    "\n",
    "Muestra un resumen de los resultados de todos los modelos\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame([popularity_metrics, content_metrics, collaborative_metrics, hybrid_metrics])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = metrics.melt('modelName', var_name='recall', value_name='values')\n",
    "\n",
    "sns.set_theme(style='whitegrid', rc={'figure.figsize':(6, 4)})  #  elige la apariencia\n",
    "sns.barplot(dfm, x=\"modelName\", y=\"values\", hue='recall', palette='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pruebas</h2>\n",
    "\n",
    "Realiza una pruebas del sistema de recomendación simulando ser el usuario -8845298781299428018 para evaluar las recomendaciones de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_interactions(person_id, test_set=True):\n",
    "    if test_set:\n",
    "        interactions_df = val_df\n",
    "    else:\n",
    "        interactions_df = train_df\n",
    "    \n",
    "    return interactions_df.loc[person_id].merge(adf, how = 'left', on = 'contentId') .sort_values('eventStrength', ascending = False)[['eventStrength', 'contentId','title', 'url', 'lang']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_interactions(, test_set=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_items(, verbose=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_cont_items(, verbose=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_collab_items(, verbose=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_hybrid_items(, verbose=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Discusión y Conclusión</h1>\n",
    "\n",
    "Presenta tus conclusiones sobre el trabajo llevado a cabo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
