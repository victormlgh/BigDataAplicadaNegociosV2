{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tarea</h1>\n",
    "<h3>Explorando la Reputación Corporativa</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Contexto</h1>\n",
    "\n",
    "En la era digital, la reputación corporativa se ha convertido en un activo crucial para las empresas, influyendo en su éxito, su capacidad para atraer talento y su relación con los consumidores. En este contexto, el análisis de sentimiento emerge como una herramienta poderosa para comprender la percepción pública de una empresa en línea.\n",
    "\n",
    "El análisis de sentimiento es una técnica que permite identificar, cuantificar y analizar las emociones y opiniones expresadas en texto, ya sea en redes sociales, reseñas de productos, artículos de noticias o cualquier otro tipo de contenido en línea. Al aplicar esta técnica al estudio de la reputación corporativa, se puede obtener una visión profunda de cómo una empresa es percibida por el público en general y cómo estas percepciones pueden influir en su imagen y desempeño.\n",
    "\n",
    "En esta serie de artículos, nos adentraremos en el emocionante campo del análisis de sentimiento aplicado a la reputación corporativa. Exploraremos cómo esta técnica puede ayudar a las empresas a monitorear la opinión pública, identificar tendencias emergentes, evaluar la satisfacción del cliente y detectar posibles problemas de reputación.\n",
    "\n",
    "<h1>Asignación</h1>\n",
    "\n",
    "Después de revisar los cuaderno sobre \"Explorando la Reputación Corporativa: Parte de Web Scraping\" y \"Explorando la Reputación Corporativa: Parte de Análisis de Sentimiento\", tenemos el objetivo de desarrollar un sistema de análisis de sentimiento basado en Big Data para explorar la reputación corporativa de de una empresa, con el fin de comprender la percepción del público y detectar tendencias y patrones relevantes.\n",
    "\n",
    "Como experto en Big Data, se le solicita desarrollar este sistema de análisis de sentimiento utilizando técnicas avanzadas de procesamiento de lenguaje natural y aprendizaje automático. El sistema deberá recopilar y analizar datos de diversas fuentes en línea, como redes sociales, foros, noticias y reseñas de productos, para identificar la opinión y el sentimiento del público hacia la Empresa.\n",
    "\n",
    "<h1>Tareas</h1>\n",
    "\n",
    "- Recopilación de datos: Obtener datos en línea de diversas fuentes relevantes para la reputación corporativa de [Nombre de la Empresa], como Twitter, Facebook, blogs, noticias, etc.\n",
    "- Preprocesamiento de datos: Limpiar y preparar los datos para su análisis, incluyendo la eliminación de ruido, la normalización de texto y la tokenización.\n",
    "- Desarrollo de algoritmos de análisis de sentimiento: Diseñar y desarrollar algoritmos de análisis de sentimiento utilizando técnicas de aprendizaje automático, como modelos de clasificación de texto y análisis de emociones.\n",
    "- Implementación del sistema: Implementar el sistema de análisis de sentimiento en una infraestructura de Big Data escalable y eficiente, asegurando su capacidad para procesar grandes volúmenes de datos en tiempo real.\n",
    "- Evaluación del sistema: Evaluar el rendimiento del sistema utilizando métricas adecuadas, como precisión, recall y F1-score, y realizar ajustes según sea necesario.\n",
    "- Generación de informes: Generar informes periódicos que resuman los resultados del análisis de sentimiento y destaquen las tendencias y patrones identificados.\n",
    "\n",
    "<h1>Código en Python</h1>\n",
    "\n",
    "En esta sección, es fundamental cargar las diferentes bibliotecas que se utilizarán en el estudio para garantizar un análisis efectivo y eficiente de los datos. A continuación, se proporciona un ejemplo de cómo podrías cargar estas bibliotecas en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, procedemos a cargar los datos utilizando la biblioteca Pandas. Puedes descargar los datos desde el aula virtual o el repositorio de <a href='https://drive.google.com/file/d/1b2o9RS4jty1ATkxszRQlmEEEdQfbM2IU/view?usp=drive_link'>datos</a>, dependiendo de tu preferencia. \n",
    "\n",
    "Primero cargamos y visalizamo los datos de los artículos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSEED=56\n",
    "\n",
    "#adf = pd.read_csv('')\n",
    "#display(adf.shape)\n",
    "#display(adf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego cargamos el conjunto de datos de users_interactions que contiene registros de interacciones de usuarios en artículos compartidos. Se puede relacionar con articles_shared.csv mediante la columna contentId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##uidf = pd.read_csv('')\n",
    "#display(uidf.shape)\n",
    "#display(uidf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Análisis exploratorio de datos</h1>\n",
    "\n",
    "Debemos convertir los datos de timestamp al formato de datetime para las interacciones de los usuarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uidf['datetime'] = pd.to_datetime(uidf['timestamp'], unit='s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos interesa graficar el número de interacciones por día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf = uidf.groupby([pd.Grouper(key='datetime', freq='D')]).agg({'eventType':'count'}).reset_index()\n",
    "\n",
    "#sns.set_theme(style='whitegrid', rc={'figure.figsize':(6, 4)})\n",
    "#plt.title('Número de interacciones por día', fontsize=13)\n",
    "#plt.xlabel('Fecha', fontsize=11)\n",
    "#plt.ylabel('Cantidad de Interacciones', fontsize=11)\n",
    "#sns.lineplot(data=gdf, y=\"eventType\", x='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos convertir los datos de timestamp al formato de datetime para los artículos\n",
    "\n",
    "Nos interesa graficar el número de artículos por día"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Divide tu data para entrenar el modelo y poder hacer pruebas de los modelos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(idf, stratify=idf['personId'], test_size=0.2, random_state=RANDOMSEED)\n",
    "\n",
    "display(train_df.shape)\n",
    "display(val_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Entrenamiento de los modelos</h1>\n",
    "\n",
    "<h2>Basado en Popularidad </h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = idf.groupby('contentId')['eventStrength'].sum().sort_values(ascending=False).reset_index()\n",
    "pop_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el primer modelo a entrenar. \n",
    "\n",
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_metrics = []\n",
    "for idx, person_id in enumerate(list(val_df.index.unique().values)):\n",
    "    person_metrics = evaluate_model_for_user(person_id)  \n",
    "    person_metrics['_person_id'] = person_id\n",
    "    people_metrics.append(person_metrics)\n",
    "\n",
    "popularity_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
    "\n",
    "popularity_recall_at_5 = popularity_df['hits@5_count'].sum() / float(popularity_df['interacted_count'].sum())\n",
    "popularity_recall_at_10 = popularity_df['hits@10_count'].sum() / float(popularity_df['interacted_count'].sum())\n",
    "\n",
    "popularity_metrics = {'modelName': 'Popularity',\n",
    "                    'recall@5': popularity_recall_at_5,\n",
    "                    'recall@10': popularity_recall_at_10}    \n",
    "\n",
    "display('Métricas de evaluación del modelo de popularidad incluyen el recall para los top 5 y top 10 recomendaciones %s' % popularity_metrics)\n",
    "popularity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h2>Basado en Contenido</h2>\n",
    "\n",
    "Revisa las funciones que utilizamos para evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n",
    "\n",
    "item_ids = adf['contentId'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(adf['title'] + \"\" + adf['text'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "display(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el modelo basado en contenido a entrenar.\n",
    "\n",
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "people_metrics = []\n",
    "for idx, person_id in enumerate(list(val_df.index.unique().values)):\n",
    "    person_metrics = evaluate_cont_model_for_user(person_id)  \n",
    "    person_metrics['_person_id'] = person_id\n",
    "    people_metrics.append(person_metrics)\n",
    "\n",
    "content_df = pd.DataFrame(people_metrics) \\\n",
    "                    .sort_values('interacted_count', ascending=False)\n",
    "\n",
    "content_recall_at_5 = content_df['hits@5_count'].sum() / float(content_df['interacted_count'].sum())\n",
    "content_recall_at_10 = content_df['hits@10_count'].sum() / float(content_df['interacted_count'].sum())\n",
    "\n",
    "content_metrics = {'modelName': 'Content',\n",
    "                    'recall@5': content_recall_at_5,\n",
    "                    'recall@10': content_recall_at_10}    \n",
    "\n",
    "print('Métricas de evaluación del modelo de contenido incluyen el recall para los top 5 y top 10 recomendaciones %s' % content_metrics)\n",
    "content_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Métodos Híbridos</h2>\n",
    "\n",
    "Revisa las funciones que utilizamos para evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid_items(person_id, items_to_ignore=[], cb_ensemble_weight=1, cf_ensemble_weight=100, verbose=False):\n",
    "        cb_recs_df = recommend_cont_items(person_id, items_to_ignore=items_to_ignore).rename(columns={'recStrength': 'recStrengthCB'})\n",
    "        cf_recs_df = recommend_collab_items(person_id, items_to_ignore=items_to_ignore).rename(columns={'recStrength': 'recStrengthCF'})\n",
    "        recs_df = cb_recs_df.merge(cf_recs_df, how = 'outer', on = 'contentId').fillna(0.0)\n",
    "        \n",
    "        recs_df['recStrengthHybrid'] = (recs_df['recStrengthCB'] * cb_ensemble_weight) + (recs_df['recStrengthCF'] * cf_ensemble_weight)\n",
    "        \n",
    "        recommendations_df = recs_df.sort_values('recStrengthHybrid', ascending=False)\n",
    "\n",
    "        if verbose:\n",
    "            recommendations_df = recommendations_df.merge(adf, how = 'left', on = 'contentId')[['recStrengthHybrid', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "        return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid_model_for_user(person_id):\n",
    "    interacted_values_testset = val_df.loc[person_id]\n",
    "    if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "        person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "    else:\n",
    "        person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "    \n",
    "    interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "    person_recs_df = recommend_hybrid_items(person_id, items_to_ignore=get_items_interacted(person_id, train_df))\n",
    "\n",
    "    hits_at_5_count = 0\n",
    "    hits_at_10_count = 0\n",
    "    for item_id in person_interacted_items_testset:\n",
    "        non_interacted_items_sample = get_not_interacted_items_sample(person_id, sample_size=100, seed=RANDOMSEED)\n",
    "\n",
    "        items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "        valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "        valid_recs = valid_recs_df['contentId'].values\n",
    "        hit_at_5, index_at_5 = verify_hit_top_n(item_id, valid_recs, 5)\n",
    "        hits_at_5_count += hit_at_5\n",
    "        hit_at_10, index_at_10 = verify_hit_top_n(item_id, valid_recs, 10)\n",
    "        hits_at_10_count += hit_at_10\n",
    "\n",
    "    recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "    recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "    person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                        'hits@10_count':hits_at_10_count, \n",
    "                        'interacted_count': interacted_items_count_testset,\n",
    "                        'recall@5': recall_at_5,\n",
    "                        'recall@10': recall_at_10}\n",
    "    return person_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir el modelo hibrido a entrenar.\n",
    "\n",
    "Nos gustaría presentar la evaluación del modelo\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_metrics = []\n",
    "for idx, person_id in enumerate(list(val_df.index.unique().values)):\n",
    "    #if idx % 100 == 0 and idx > 0:\n",
    "    #    print('%d users processed' % idx)\n",
    "    person_metrics = evaluate_hybrid_model_for_user(person_id)  \n",
    "    person_metrics['_person_id'] = person_id\n",
    "    people_metrics.append(person_metrics)\n",
    "\n",
    "hybrid_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
    "\n",
    "hybrid_recall_at_5 = hybrid_df['hits@5_count'].sum() / float(hybrid_df['interacted_count'].sum())\n",
    "hybrid_recall_at_10 = hybrid_df['hits@10_count'].sum() / float(hybrid_df['interacted_count'].sum())\n",
    "\n",
    "hybrid_metrics = {'modelName': 'Hybrid',\n",
    "                    'recall@5': hybrid_recall_at_5,\n",
    "                    'recall@10': hybrid_recall_at_10}    \n",
    "\n",
    "print('Métricas de evaluación del modelo hibrido incluyen el recall para los top 5 y top 10 recomendaciones %s' % hybrid_metrics)\n",
    "hybrid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Resultado</h1>\n",
    "\n",
    "Muestra un resumen de los resultados de todos los modelos\n",
    "\n",
    "¿Podrías explicar lo que entiendes del resulato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame([popularity_metrics, content_metrics, collaborative_metrics, hybrid_metrics])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = metrics.melt('modelName', var_name='recall', value_name='values')\n",
    "\n",
    "sns.set_theme(style='whitegrid', rc={'figure.figsize':(6, 4)})  #  elige la apariencia\n",
    "sns.barplot(dfm, x=\"modelName\", y=\"values\", hue='recall', palette='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pruebas</h2>\n",
    "\n",
    "Realiza una pruebas del sistema de recomendación simulando ser el usuario -8845298781299428018 para evaluar las recomendaciones de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_interactions(person_id, test_set=True):\n",
    "    if test_set:\n",
    "        interactions_df = val_df\n",
    "    else:\n",
    "        interactions_df = train_df\n",
    "    \n",
    "    return interactions_df.loc[person_id].merge(adf, how = 'left', on = 'contentId') .sort_values('eventStrength', ascending = False)[['eventStrength', 'contentId','title', 'url', 'lang']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Discusión y Conclusión</h1>\n",
    "\n",
    "Presenta tus conclusiones sobre el trabajo llevado a cabo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
